{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,6,7\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/mnt/iMVR/junde/.cache/huggingface/hub'\n",
    "\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "import networkx as nx\n",
    "from transformers import pipeline\n",
    "import re\n",
    "from creat import creat_world\n",
    "from prompt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.28s/it]\n"
     ]
    }
   ],
   "source": [
    "pipeline = pipeline(model=\"meta-llama/Llama-2-7b-chat-hf\", device_map=\"auto\")\n",
    "model = HuggingFacePipeline(pipeline=pipeline, model_kwargs={'temperature':0.7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are creating a new agent: Toblen Stonehill\n",
      "Name: Toblen Stonehill (age: 69)\n",
      "Innate traits: mean, gossipy, arrogant, selfish\n",
      "Toblen owns a trading post.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are creating a new agent: Daran Edermath\n",
      "Name: Daran Edermath (age: 55)\n",
      "Innate traits: Stubborn, upright, inarticulate, calm\n",
      "Daran is a retired adventurer who lives in a tidy little cottage beside an apple orchard. A fit, silver-haired half-elf well over a hundred years old, Daran is a fighter who served as a marshal and herald for many years in the lands of the Dragon Coast, far to the southeast. Upon retiring, he returned to the Neverwinter region, his original home.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are creating a new agent: Linene Graywind\n",
      "Name: Linene Graywind (age: 38)\n",
      "Innate traits: competent, forbearing, self-discipline, impressionable \n",
      "Linene runs a trading post.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are creating a new agent: Halia Thornton\n",
      "Name: Halia Thornton (age: 33)\n",
      "Innate traits: ambitious and calculating\n",
      "She is the guildmaster of Phandalin Miner’s Exchange, a trading post where local miners have their valuable finds weighed, measured, and paid out. In her attempts to establish the Miner's Exchange as the closest thing the town has to a governing authority, she acts as more than a simple merchant.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are creating a new agent: Qelline Alderleaf\n",
      "Name: Qelline Alderleaf (age: 45)\n",
      "Innate traits: wise\n",
      "Qelline is a wise female halfling of forty-five, and is a pragmatic farmer who seems to know everything that goes on in town. She is a kind host, and is willing to let the characters stay in her hayloft if they don't want to stay at the Stonehill Inn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are creating a new agent: Sister Garaele\n",
      "Name: Sister Garaele (age: 18)\n",
      "Innate traits: kind-hearted, innocent, pure\n",
      "Sister Garaele is an elf cleric of Tymora and a Harper agent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are creating a new agent: Harbin Wester\n",
      "Name: Harbin Wester (age: 40)\n",
      "Innate traits: pompous\n",
      "Harbin is the townmaster of Phandalin. A pompous, old food. Phandalin has no functioning government, but the townsfolk elect someone to serve as townmaster each year. The townmaster serves as a judge in minor disputes and keeps any records that need to be kept.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are creating a new agent: Terrill Bloodscar\n",
      "Name: Terrill Bloodscar (age: 16)\n",
      "Innate traits: ignorant\n",
      "Terrill is a human ruffian. He wears a grimy scarlet cloak. He is a member of the Redbrand ruffians. He doesn't like adventurers, and wants to rob and kill them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are creating a new agent: Conrad Scarface\n",
      "Name: Conrad Scarface (age: 19)\n",
      "Innate traits: barbaric\n",
      "Conrad is a human ruffian. He wears a grimy scarlet cloak. He is a member of the Redbrand ruffians. He doesn't like adventurers, and wants to rob and kill them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are creating a new agent: Nellie Starsmith\n",
      "Name: Nellie Starsmith (age: 23)\n",
      "Innate traits: foxy\n",
      "Nellie is a human ruffian. She wears a grimy scarlet cloak. She is a member of the Redbrand ruffians. She doesn't like adventurers, and wants to rob and kill them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are creating a new agent: Valerie Grinblade\n",
      "Name: Valerie Grinblade (age: 27)\n",
      "Innate traits: ruthless\n",
      "Valerie is a human ruffian. She wears a grimy scarlet cloak. She is a member of the Redbrand ruffians. She doesn't like adventurers, and wants to rob and kill them.\n"
     ]
    }
   ],
   "source": [
    "locations, agents = creat_world(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In global time 1\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 16.56 MiB is free. Process 3439896 has 17.22 GiB memory in use. Including non-PyTorch memory, this process has 6.42 GiB memory in use. Of the allocated memory 6.09 GiB is allocated by PyTorch, and 84.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m people: \n\u001b[1;32m     17\u001b[0m   \u001b[39mif\u001b[39;00m i \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m action_results: \u001b[39m# initialize action results as the observations\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     action_results[i] \u001b[39m=\u001b[39m agents[i]\u001b[39m.\u001b[39;49mget_summary(force_refresh\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     19\u001b[0m   people_description\u001b[39m.\u001b[39mappend(i\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m action_results[i])\n\u001b[1;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m people: \u001b[39m# add observation to memory and react\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/iMVR/junde/generative_agents_mine/langchain_experimental/generative_agents/generative_agent.py:230\u001b[0m, in \u001b[0;36mGenerativeAgent.get_summary\u001b[0;34m(self, force_refresh, now)\u001b[0m\n\u001b[1;32m    224\u001b[0m since_refresh \u001b[39m=\u001b[39m (current_time \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_refreshed)\u001b[39m.\u001b[39mseconds\n\u001b[1;32m    225\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    226\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msummary\n\u001b[1;32m    227\u001b[0m     \u001b[39mor\u001b[39;00m since_refresh \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msummary_refresh_seconds\n\u001b[1;32m    228\u001b[0m     \u001b[39mor\u001b[39;00m force_refresh\n\u001b[1;32m    229\u001b[0m ):\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msummary \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_agent_summary()\n\u001b[1;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_refreshed \u001b[39m=\u001b[39m current_time\n\u001b[1;32m    232\u001b[0m age \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mage \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mage \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mN/A\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/mnt/iMVR/junde/generative_agents_mine/langchain_experimental/generative_agents/generative_agent.py:215\u001b[0m, in \u001b[0;36mGenerativeAgent._compute_agent_summary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m prompt \u001b[39m=\u001b[39m PromptTemplate\u001b[39m.\u001b[39mfrom_template(\n\u001b[1;32m    206\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mHow would you summarize \u001b[39m\u001b[39m{name}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39ms core characteristics given the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m     \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m following statements:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mSummary: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m )\n\u001b[1;32m    212\u001b[0m \u001b[39m# The agent seeks to think about their core characteristics.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    214\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchain(prompt)\n\u001b[0;32m--> 215\u001b[0m     \u001b[39m.\u001b[39;49mrun(name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, queries\u001b[39m=\u001b[39;49m[\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39ms core characteristics\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    216\u001b[0m     \u001b[39m.\u001b[39mstrip()\n\u001b[1;32m    217\u001b[0m )\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/langchain/chains/base.py:510\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[1;32m    506\u001b[0m         _output_key\n\u001b[1;32m    507\u001b[0m     ]\n\u001b[1;32m    509\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m--> 510\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[1;32m    511\u001b[0m         _output_key\n\u001b[1;32m    512\u001b[0m     ]\n\u001b[1;32m    514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    515\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    516\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    517\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but none were provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    518\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/langchain/chains/base.py:286\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    251\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    252\u001b[0m     inputs: Union[Dict[\u001b[39mstr\u001b[39m, Any], Any],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m     include_run_info: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    260\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m    261\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \n\u001b[1;32m    263\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39m            `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprep_inputs(inputs)\n\u001b[1;32m    287\u001b[0m     callback_manager \u001b[39m=\u001b[39m CallbackManager\u001b[39m.\u001b[39mconfigure(\n\u001b[1;32m    288\u001b[0m         callbacks,\n\u001b[1;32m    289\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata,\n\u001b[1;32m    295\u001b[0m     )\n\u001b[1;32m    296\u001b[0m     new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/langchain/chains/base.py:441\u001b[0m, in \u001b[0;36mChain.prep_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    439\u001b[0m     inputs \u001b[39m=\u001b[39m {\u001b[39mlist\u001b[39m(_input_keys)[\u001b[39m0\u001b[39m]: inputs}\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     external_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmemory\u001b[39m.\u001b[39;49mload_memory_variables(inputs)\n\u001b[1;32m    442\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mexternal_context)\n\u001b[1;32m    443\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_inputs(inputs)\n",
      "File \u001b[0;32m/mnt/iMVR/junde/generative_agents_mine/langchain_experimental/generative_agents/memory.py:265\u001b[0m, in \u001b[0;36mGenerativeAgentMemory.load_memory_variables\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    263\u001b[0m now \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnow_key)\n\u001b[1;32m    264\u001b[0m \u001b[39mif\u001b[39;00m queries \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     relevant_memories \u001b[39m=\u001b[39m [\n\u001b[1;32m    266\u001b[0m         mem \u001b[39mfor\u001b[39;49;00m query \u001b[39min\u001b[39;49;00m queries \u001b[39mfor\u001b[39;49;00m mem \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetch_memories(query, now\u001b[39m=\u001b[39;49mnow)\n\u001b[1;32m    267\u001b[0m     ]\n\u001b[1;32m    268\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    269\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelevant_memories_key: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_memories_detail(\n\u001b[1;32m    270\u001b[0m             relevant_memories\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m         ),\n\u001b[1;32m    275\u001b[0m     }\n\u001b[1;32m    277\u001b[0m most_recent_memories_token \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmost_recent_memories_token_key)\n",
      "File \u001b[0;32m/mnt/iMVR/junde/generative_agents_mine/langchain_experimental/generative_agents/memory.py:266\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    263\u001b[0m now \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnow_key)\n\u001b[1;32m    264\u001b[0m \u001b[39mif\u001b[39;00m queries \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m     relevant_memories \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 266\u001b[0m         mem \u001b[39mfor\u001b[39;00m query \u001b[39min\u001b[39;00m queries \u001b[39mfor\u001b[39;00m mem \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetch_memories(query, now\u001b[39m=\u001b[39;49mnow)\n\u001b[1;32m    267\u001b[0m     ]\n\u001b[1;32m    268\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    269\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelevant_memories_key: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_memories_detail(\n\u001b[1;32m    270\u001b[0m             relevant_memories\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m         ),\n\u001b[1;32m    275\u001b[0m     }\n\u001b[1;32m    277\u001b[0m most_recent_memories_token \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmost_recent_memories_token_key)\n",
      "File \u001b[0;32m/mnt/iMVR/junde/generative_agents_mine/langchain_experimental/generative_agents/memory.py:229\u001b[0m, in \u001b[0;36mGenerativeAgentMemory.fetch_memories\u001b[0;34m(self, observation, now)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_retriever\u001b[39m.\u001b[39mget_relevant_documents(observation)\n\u001b[1;32m    228\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmemory_retriever\u001b[39m.\u001b[39;49mget_relevant_documents(observation)\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/langchain/schema/retriever.py:211\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    210\u001b[0m     run_manager\u001b[39m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 211\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    212\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     run_manager\u001b[39m.\u001b[39mon_retriever_end(\n\u001b[1;32m    214\u001b[0m         result,\n\u001b[1;32m    215\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    216\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/langchain/schema/retriever.py:204\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m _kwargs \u001b[39m=\u001b[39m kwargs \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expects_other_args \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m    203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 204\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_relevant_documents(\n\u001b[1;32m    205\u001b[0m         query, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_kwargs\n\u001b[1;32m    206\u001b[0m     )\n\u001b[1;32m    207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_relevant_documents(query, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/langchain/retrievers/time_weighted_retriever.py:101\u001b[0m, in \u001b[0;36mTimeWeightedVectorStoreRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m     96\u001b[0m docs_and_scores \u001b[39m=\u001b[39m {\n\u001b[1;32m     97\u001b[0m     doc\u001b[39m.\u001b[39mmetadata[\u001b[39m\"\u001b[39m\u001b[39mbuffer_idx\u001b[39m\u001b[39m\"\u001b[39m]: (doc, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_salience)\n\u001b[1;32m     98\u001b[0m     \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_stream[\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk :]\n\u001b[1;32m     99\u001b[0m }\n\u001b[1;32m    100\u001b[0m \u001b[39m# If a doc is considered salient, update the salience score\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m docs_and_scores\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_salient_docs(query))\n\u001b[1;32m    102\u001b[0m rescored_docs \u001b[39m=\u001b[39m [\n\u001b[1;32m    103\u001b[0m     (doc, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_combined_score(doc, relevance, current_time))\n\u001b[1;32m    104\u001b[0m     \u001b[39mfor\u001b[39;00m doc, relevance \u001b[39min\u001b[39;00m docs_and_scores\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m    105\u001b[0m ]\n\u001b[1;32m    106\u001b[0m rescored_docs\u001b[39m.\u001b[39msort(key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m1\u001b[39m], reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/langchain/retrievers/time_weighted_retriever.py:80\u001b[0m, in \u001b[0;36mTimeWeightedVectorStoreRetriever.get_salient_docs\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return documents that are salient to the query.\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m docs_and_scores: List[Tuple[Document, \u001b[39mfloat\u001b[39m]]\n\u001b[0;32m---> 80\u001b[0m docs_and_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvectorstore\u001b[39m.\u001b[39;49msimilarity_search_with_relevance_scores(\n\u001b[1;32m     81\u001b[0m     query, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msearch_kwargs\n\u001b[1;32m     82\u001b[0m )\n\u001b[1;32m     83\u001b[0m results \u001b[39m=\u001b[39m {}\n\u001b[1;32m     84\u001b[0m \u001b[39mfor\u001b[39;00m fetched_doc, relevance \u001b[39min\u001b[39;00m docs_and_scores:\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/langchain/schema/vectorstore.py:306\u001b[0m, in \u001b[0;36mVectorStore.similarity_search_with_relevance_scores\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return docs and relevance scores in the range [0, 1].\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \n\u001b[1;32m    292\u001b[0m \u001b[39m0 is dissimilar, 1 is most similar.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39m    List of Tuples of (doc, similarity_score)\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    304\u001b[0m score_threshold \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mscore_threshold\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 306\u001b[0m docs_and_similarities \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_similarity_search_with_relevance_scores(\n\u001b[1;32m    307\u001b[0m     query, k\u001b[39m=\u001b[39;49mk, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    308\u001b[0m )\n\u001b[1;32m    309\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[1;32m    310\u001b[0m     similarity \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m similarity \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[1;32m    311\u001b[0m     \u001b[39mfor\u001b[39;00m _, similarity \u001b[39min\u001b[39;00m docs_and_similarities\n\u001b[1;32m    312\u001b[0m ):\n\u001b[1;32m    313\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    314\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRelevance scores must be between\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    315\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m 0 and 1, got \u001b[39m\u001b[39m{\u001b[39;00mdocs_and_similarities\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    316\u001b[0m     )\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/langchain/vectorstores/faiss.py:1125\u001b[0m, in \u001b[0;36mFAISS._similarity_search_with_relevance_scores\u001b[0;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[39mif\u001b[39;00m relevance_score_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1122\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnormalize_score_fn must be provided to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1123\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m FAISS constructor to normalize scores\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1124\u001b[0m     )\n\u001b[0;32m-> 1125\u001b[0m docs_and_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msimilarity_search_with_score(\n\u001b[1;32m   1126\u001b[0m     query,\n\u001b[1;32m   1127\u001b[0m     k\u001b[39m=\u001b[39;49mk,\n\u001b[1;32m   1128\u001b[0m     \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m,\n\u001b[1;32m   1129\u001b[0m     fetch_k\u001b[39m=\u001b[39;49mfetch_k,\n\u001b[1;32m   1130\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1131\u001b[0m )\n\u001b[1;32m   1132\u001b[0m docs_and_rel_scores \u001b[39m=\u001b[39m [\n\u001b[1;32m   1133\u001b[0m     (doc, relevance_score_fn(score)) \u001b[39mfor\u001b[39;00m doc, score \u001b[39min\u001b[39;00m docs_and_scores\n\u001b[1;32m   1134\u001b[0m ]\n\u001b[1;32m   1135\u001b[0m \u001b[39mreturn\u001b[39;00m docs_and_rel_scores\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/langchain/vectorstores/faiss.py:390\u001b[0m, in \u001b[0;36mFAISS.similarity_search_with_score\u001b[0;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity_search_with_score\u001b[39m(\n\u001b[1;32m    370\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    371\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    376\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Tuple[Document, \u001b[39mfloat\u001b[39m]]:\n\u001b[1;32m    377\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \n\u001b[1;32m    379\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39m        L2 distance in float. Lower score represents more similarity.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m     embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embed_query(query)\n\u001b[1;32m    391\u001b[0m     docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimilarity_search_with_score_by_vector(\n\u001b[1;32m    392\u001b[0m         embedding,\n\u001b[1;32m    393\u001b[0m         k,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    397\u001b[0m     )\n\u001b[1;32m    398\u001b[0m     \u001b[39mreturn\u001b[39;00m docs\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/langchain/vectorstores/faiss.py:155\u001b[0m, in \u001b[0;36mFAISS._embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_function\u001b[39m.\u001b[39membed_query(text)\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_function(text)\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/langchain/embeddings/huggingface.py:105\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed_query\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m     97\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute query embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \n\u001b[1;32m     99\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39m        Embeddings for the text.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_documents([text])[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/langchain/embeddings/huggingface.py:92\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     90\u001b[0m     sentence_transformers\u001b[39m.\u001b[39mSentenceTransformer\u001b[39m.\u001b[39mstop_multi_process_pool(pool)\n\u001b[1;32m     91\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mencode(texts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode_kwargs)\n\u001b[1;32m     94\u001b[0m \u001b[39mreturn\u001b[39;00m embeddings\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:153\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     device \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_target_device\n\u001b[0;32m--> 153\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m    155\u001b[0m all_embeddings \u001b[39m=\u001b[39m []\n\u001b[1;32m    156\u001b[0m length_sorted_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort([\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_text_length(sen) \u001b[39mfor\u001b[39;00m sen \u001b[39min\u001b[39;00m sentences])\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 810 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/mnt/iMVR/junde/miniconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.68 GiB of which 16.56 MiB is free. Process 3439896 has 17.22 GiB memory in use. Including non-PyTorch memory, this process has 6.42 GiB memory in use. Of the allocated memory 6.09 GiB is allocated by PyTorch, and 84.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "global_time = 0\n",
    "for repeats in range(5):\n",
    "  global_time += 1\n",
    "  print(\"In global time\", global_time)\n",
    "  action_prompts = {}\n",
    "  action_results = {}\n",
    "  for location in town_areas.keys():\n",
    "    people = []\n",
    "    for i in town_people.keys():\n",
    "      if locations[i] == location:\n",
    "        people.append(i)\n",
    "    \n",
    "    # for name in people:\n",
    "      # prompt = \"You are {}. Your plans are: {}. You are currently in {} with the following description: {}. Your memories are: {}. It is currently {}:00. The following people are in this area: {}. You can interact with them.\".format(name, plans[name], location, town_areas[location], '\\n'.join(compressed_memories_all[name][-5:]), str(global_time), ', '.join(people))\n",
    "    people_description = []\n",
    "    for i in people: \n",
    "      if i not in action_results: # initialize action results as the observations\n",
    "        action_results[i] = agents[i].get_summary(force_refresh=True)\n",
    "      people_description.append(i+': '+ action_results[i])\n",
    "\n",
    "\n",
    "    for i in people: # add observation to memory and react\n",
    "      observation = \"You are {}.You are currently in {} with the following description: {}. \\\n",
    "      It is currently {}:00. The following people are in this area: {}. You can interact with them.\". \\\n",
    "      format(i, location, town_areas[location], str(global_time), ', '.join(people))\n",
    "\n",
    "      observation += ' You know the following about people: ' + '. '.join(people_description)\n",
    "\n",
    "      agents[i].memory.add_memory(observation)\n",
    "      _, reaction = agents[i].generate_reaction(observation)\n",
    "      action_results[i] = reaction\n",
    "      print(reaction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
